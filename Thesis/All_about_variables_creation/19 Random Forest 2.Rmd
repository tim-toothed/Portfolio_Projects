---
title: "19 Random Forest 2"
author: "Timur Sharifullin"
date: "2023-04-23"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(dplyr)
library(randomForest)
```

# Загрузка Данных
```{r}
final_df = read.csv("fin_df_distance.csv")
final_df = final_df[,-1]
final_df$X = factor(final_df$X, levels = c("none","hit"))
final_df$artist_name = as.factor(final_df$artist_name) 
final_df1 = final_df[,c(3, 5, 18, 21:30)]
```


# Hypothesis 1. Биография - предшествующих успех.

**The success of a given song is positively associated with the number of successful songs previously released by the artist, such that a higher number of previous successful songs in the artist's discography may increase the likelihood of the given song achieving chart success.**

Данная гипотеза может быть проверена при использовании логистической регрессии, так как гипотеза подразумевает линейное отношение между dependent и independent variable.

Единица анализа - трек 
Dependent Variable - X
Independent Variable - hit_n
Модель - Логистическая Регрессия

## Rule of Thumb

В данном случае в анализе участвует переменная, имеющая два класса, и только одна независимая переменная. Это значит, что соответствуясь Rule of Thumb для регрессионных моделей, должно быть минимум 10 обзерваций из каждого класса

```{r}
barn = final_df1[!duplicated(final_df1[,c(1,3)]),] %>% group_by(hit_n,X) %>% summarize(n = n())
barn

barn %>%
  ggplot(aes(x = hit_n, y = n, fill = X)) +
  geom_bar(position="stack", stat="identity") +
  scale_x_continuous(breaks = seq(0,30,1)) +
  scale_y_continuous(breaks = seq(0,200,10)) +
  coord_cartesian(xlim = c(0,30), ylim = c(0,170))
```

До 11 хита - всё точно подходит

```{r}
barn %>%
  ggplot(aes(x = hit_n, y = n, fill = X)) +
  geom_bar(position="stack", stat="identity") +
  scale_x_continuous(breaks = seq(11,30,1)) +
  scale_y_continuous(breaks = seq(0,50,2)) +
  coord_cartesian(xlim = c(14,30), ylim = c(0,50))
```

Можно взять до 16 хитов - далее Rule of Thumb не работает.

## Models

```{r}
model = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n, family = "binomial")

# logit 

m_logit = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n,
              family = binomial(link = "logit"))

# probit

m_probit = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n,
              family = binomial(link = "probit"))

# cauchit

m_cauchit = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n,
              family = binomial(link = "cauchit"))

# log

m_log = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n,
              family = binomial(link = "log"))

# cloglog (complementary log-log)

m_cloglog = glm(data = filter(final_df1,hit_n<=16), formula = X ~ hit_n,
              family = binomial(link = "cloglog"))

```

```{r}
summary(m_logit)
summary(m_probit)
summary(model)
summary(m_cauchit)
summary(m_log)
summary(m_cloglog)
```

### Model comparison

The AIC is not really different, but the second model (m_probit) works the best, m_log is only forth.

```{r}
library(rcompanion)
compareGLM(m_logit,m_probit,m_cauchit,m_log,m_cloglog)
```
m_probit is the best again.

```{r}
library(pROC)
# Splitting the data
ds3 = filter(final_df1, hit_n <= 16)[,2:3]
set.seed(1)

# using 70% of ds as training set and 30% as test set
sample = sample(c(TRUE, FALSE), nrow(ds3), replace=TRUE, prob=c(0.7,0.3))
train  = ds3[sample, ]
test   = ds3[!sample, ]

# Creating ROC Curve Plot

## Probit
m_probit = glm(data = train, formula = X ~ hit_n,
              family = binomial(link = "probit"))
test_probit = predict(m_probit, newdata = test, type = "response")
test_roc_prob = roc(test$X ~ test_probit, plot = TRUE, print.auc = TRUE)
```


# Разделение на subsets
```{r}
ds0 = final_df1 %>% filter(hit_n == 0) %>% select(-hit_n)
ds1 = final_df1 %>% filter(hit_n == 1) %>% select(-hit_n)
ds2 = final_df1 %>% filter(hit_n == 2) %>% select(-hit_n)
ds3 = final_df1 %>% filter(hit_n == 3) %>% select(-hit_n)

ds4 = final_df1 %>% filter(hit_n == 4) %>% select(-hit_n)
ds5 = final_df1 %>% filter(hit_n == 5) %>% select(-hit_n)
ds6 = final_df1 %>% filter(hit_n == 6) %>% select(-hit_n)
ds7 = final_df1 %>% filter(hit_n == 7) %>% select(-hit_n)

ds8 = final_df1 %>% filter(hit_n == 8) %>% select(-hit_n)
ds9 = final_df1 %>% filter(hit_n == 9) %>% select(-hit_n)
ds10 = final_df1 %>% filter(hit_n == 10) %>% select(-hit_n)
ds11 = final_df1 %>% filter(hit_n == 11) %>% select(-hit_n)
```

# Descriptive Stats

```{r}
paste("Статус - 0 хитов, Количество уникальных артистов:", length(unique(ds0$artist_name)), "|", length(unique(ds0$artist_name))/282*100, "%")
paste("Статус - 1 хит  , Количество уникальных артистов:", length(unique(ds1$artist_name)), "|", round(length(unique(ds1$artist_name))/282,2)*100, "%")
paste("Статус - 2 хита , Количество уникальных артистов:", length(unique(ds2$artist_name)), "|", round(length(unique(ds2$artist_name))/282,2)*100, "%")
paste("Статус - 3 хита , Количество уникальных артистов:", length(unique(ds3$artist_name)), "|", round(length(unique(ds3$artist_name))/282,2)*100, "%")
paste("Статус - 4 хита , Количество уникальных артистов:", length(unique(ds4$artist_name)), "|", round(length(unique(ds4$artist_name))/282,2)*100, "%")

paste("Статус - 5 хитов, Количество уникальных артистов:", length(unique(ds5$artist_name)), "|", round(length(unique(ds5$artist_name))/282,2)*100, "%")
paste("Статус - 6 хитов, Количество уникальных артистов:", length(unique(ds6$artist_name)), "|", round(length(unique(ds6$artist_name))/282,2)*100, "%")
paste("Статус - 7 хитов, Количество уникальных артистов:", length(unique(ds7$artist_name)), "|", round(length(unique(ds7$artist_name))/282,2)*100, "%")
paste("Статус - 8 хитов, Количество уникальных артистов:", length(unique(ds8$artist_name)), "|", round(length(unique(ds8$artist_name))/282,2)*100, "%")

paste("Статус - 9 хитов, Количество уникальных артистов:", length(unique(ds9$artist_name)), "|", round(length(unique(ds9$artist_name))/282,2)*100, "%")
paste("Статус - 10 хитов,Количество уникальных артистов:", length(unique(ds10$artist_name)), "|", round(length(unique(ds10$artist_name))/282,2)*100, "%")
paste("Статус - 11 хитов,Количество уникальных артистов:", length(unique(ds11$artist_name)), "|", round(length(unique(ds11$artist_name))/282,2)*100, "%")
```

```{r}
n_artists_status = final_df1 %>% group_by(hit_n, artist_name) %>% summarize(n()) %>% group_by(hit_n) %>% summarize(unique_artists = n())

n_artists_status %>% ggplot() + geom_line(aes(x = hit_n, y=unique_artists))
n_artists_status$hit_n = n_artists_status$hit_n+1
n_artists_status$Freq = n_artists_status$unique_artists/282
n_artists_status$Lotka = round(282/(n_artists_status$hit_n^0.9),0)
n_artists_status

n_artists_status %>% ggplot() + geom_line(aes(x = hit_n, y=unique_artists)) + geom_line(aes(x = hit_n, y=Lotka,col = "red"))
```





```{r}
plot_data = final_df1
plot_data$prob <- predict(m_log, newdata = final_df1, type = "response")
ggplot(plot_data, aes(x = hit_n, y = prob)) +
  geom_line() +
  labs(x = "Number of previous hits", y = "Probability of a hit")
```

```{r}
final_df1
```


```{r}
forestsrc = rfsrc(formula = X ~ .,
                  data = ds0,
                  ntree = 5000,
                  importance="permute",
                  proximity = "all",
                  seed = 2023,
                  splitrule="auc")

forestsrc
```



