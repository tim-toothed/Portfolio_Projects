---
title: "16 Similarity"
author: "Timur Sharifullin"
date: "2023-04-12"
output: html_document
---

```{r setup, include=FALSE}
library(dplyr)
library(stringr)
library(ggplot2)
library(lubridate)

knitr::opts_chunk$set(echo = TRUE)
final_df = read.csv("final_df1.csv") 
final_df$X = as.factor(final_df$X)
final_df = final_df[year(final_df$album_release_date) == 2022,]
row.names(final_df) = NULL
```

```{r}
#df = data.frame(name = paste(final_df$artist_name, "-", final_df$track_name), 
#             tonnetz_std = final_df$tonnetz_std, 
#             link = final_df$file_link) %>%
#  arrange(-tonnetz_std)


#datatable(df[,1:2])
```

```{r}
#n = 10010
#audio_play = readMP3(df$link[n])
#df$name[n]
#play(audio_play) 
```


1. *rmsP_median* - the more intense and energetic beat (Rock or Hard Electronic Instrumentals have higher values, classic trap, rnb, voice only audio messages or instrumentals without drums have lower values)
2. *rmsP_std* - the loudness of the harmonic content changes frequently (hyperpop or parts with changing drum patterns have higher values, pop/dance, voice only audio messages or instrumentals without drums (music with stable drum pattern) have lower values)
3. *contrast_median* - simple music (mostly positive) with one or two instruments has higher values of contrast_median, while songs with instrumental overload, complex multi-layered instrumental (in terms of the number of instruments, not in terms of the notes played) have lower values
4. *contrast_std* - the more variability in sound and therefore - more complexity. Songs where many instruments  change each other (very tonally dynamic, do not become a single layer, as in the case of a low contrast_median) have higher values, music with same sounds/instruments all along the whole song typically has lower values 
5. *tonnetz_median* - A higher median value suggests a more complex harmonic structure with more notes in the tonal system. Conversely, a lower median value suggests a simpler harmonic structure with fewer notes in the tonal system. So, songs with higher tonnetz_median would have more rich sound in terms of notes mixing, while songs with lower tonnetz_median would sound less interesting, but more catchy and simpler due to lack of tonal textures.
6. *tonnetz_std* - A higher standard deviation indicate that the song has more complex tonal relationships or a greater variety of musical elements. On the other hand, a lower standard deviation may suggest a simpler or more repetitive tonal structure.
7. *sound_brightness_noisiness* 
8. *laid_back_groovy_lyrical*
9. *quiet_and_melodic*
10. *overall_spectral_Variability*

```{r}
names = paste(seq(1,nrow(final_df)), final_df$artist_name, "-", final_df$track_name)
```

## rmsP_median

```{r}
df_matrix = matrix(final_df$rmsP_median)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_rmsP_median = df %>% group_by(col) %>% summarize(median_sim = median(value))
```


## rmsP_std

```{r}
df_matrix = matrix(final_df$rmsP_std)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_rmsP_std = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## contrast_median

```{r}
df_matrix = matrix(final_df$contrast_median)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_contrast_median = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## contrast_std

```{r}
df_matrix = matrix(final_df$contrast_std)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_contrast_std = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## tonnetz_median

```{r}
df_matrix = matrix(final_df$tonnetz_median)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_tonnetz_median = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## tonnetz_std

```{r}
df_matrix = matrix(final_df$tonnetz_std)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_tonnetz_std = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## sound_brightness_noisiness

```{r}
df_matrix = matrix(final_df$sound_brightness_noisiness)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_sound_brightness_noisiness = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## laid_back_groovy_lyrical

```{r}
df_matrix = matrix(final_df$laid_back_groovy_lyrical)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_laid_back_groovy_lyrical = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## quiet_and_melodic

```{r}
df_matrix = matrix(final_df$quiet_and_melodic)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_quiet_and_melodic = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## overall_spectral_Variability

```{r}
df_matrix = matrix(final_df$overall_spectral_Variability)
row.names(df_matrix) = names
d = dist(df_matrix, method="euclidean")

df <- melt(as.matrix(d), varnames = c("row", "col"))
df = df[df$value != 0,] 

med_dist_overall_spectral_Variability = df %>% group_by(col) %>% summarize(median_sim = median(value))
```

## Final Table

```{r}
fin_df = final_df[,-c(18:23,27:30)]

fin_df$rmsP_median = as.numeric(as.data.frame(med_dist_rmsP_median[,2])[,1])
fin_df$rmsP_std = as.numeric(as.data.frame(med_dist_rmsP_std[,2])[,1])
fin_df$contrast_median = as.numeric(as.data.frame(med_dist_contrast_median[,2])[,1])
fin_df$contrast_std = as.numeric(as.data.frame(med_dist_contrast_std[,2])[,1])
fin_df$tonnetz_median = as.numeric(as.data.frame(med_dist_tonnetz_median[,2])[,1])
fin_df$tonnetz_std = as.numeric(as.data.frame(med_dist_tonnetz_std[,2])[,1])
fin_df$sound_brightness_noisiness = as.numeric(as.data.frame(med_dist_sound_brightness_noisiness[,2])[,1])
fin_df$laid_back_groovy_lyrical = as.numeric(as.data.frame(med_dist_laid_back_groovy_lyrical[,2])[,1])
fin_df$quiet_and_melodic = as.numeric(as.data.frame(med_dist_quiet_and_melodic[,2])[,1])
fin_df$overall_spectral_variability = as.numeric(as.data.frame(med_dist_overall_spectral_Variability[,2])[,1])
row.names(fin_df) = NULL
head(fin_df)
```

```{r}
write.csv(fin_df, "fin_df_distance2022.csv",row.names = F)
```


