{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run this cell first - it will load every required package/model { display-mode: \"form\" }\n",
    "\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "  import whisper as wp\n",
    "except ImportError:\n",
    "  ! pip install -U openai-whisper\n",
    "\n",
    "try:\n",
    "  from simple_diarizer.diarizer import Diarizer\n",
    "except ImportError:\n",
    "  ! pip install simple-diarizer\n",
    "\n",
    "try:\n",
    "  subprocess.run(['ffmpeg', '-version'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, check=True)\n",
    "except subprocess.CalledProcessError:\n",
    "  ! apt install ffmpeg\n",
    "  ! pip install ffmpeg\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ----------------------MAIN SETUP--------------------------------\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "import whisper as wp\n",
    "import pandas as pd\n",
    "from simple_diarizer.diarizer import Diarizer\n",
    "import os\n",
    "\n",
    "model = wp.load_model('large-v2')\n",
    "\n",
    "def perform_diarization(audio_path, num_speakers):\n",
    "    diarizer = Diarizer(embed_model='xvec', cluster_method='sc')\n",
    "    speaker_segments = diarizer.diarize(audio_path, num_speakers=num_speakers)\n",
    "\n",
    "    segments_df = pd.DataFrame(speaker_segments)\n",
    "    unique_speakers = segments_df['label'].drop_duplicates().reset_index()['label']\n",
    "    speaker_dict = dict((v, k + 1) for k, v in unique_speakers.items())\n",
    "\n",
    "    segments_df['speaker'] = segments_df['label'].replace(speaker_dict)\n",
    "    return segments_df\n",
    "\n",
    "def convert_audio_to_dataframe(audio_path):\n",
    "    preprocess_audio(audio_path)\n",
    "    result = model.transcribe('mono.wav',\n",
    "                              fp16 = False,\n",
    "                              language='Russian',\n",
    "                              verbose=True,\n",
    "                              without_timestamps=False,\n",
    "                              initial_prompt=\"Здравствуйте, добро пожаловать!\")\n",
    "    transcript_df = pd.DataFrame(result['segments'])\n",
    "    return transcript_df\n",
    "\n",
    "def preprocess_audio(input_path):\n",
    "    command = f\"ffmpeg -y -i {input_path} -acodec pcm_s16le -ar 16000 -ac 1 mono.wav\"\n",
    "    os.system(command)\n",
    "\n",
    "def format_transcript(row):\n",
    "    text = row['text'].replace('\\n', '')\n",
    "    speaker = row['speaker']\n",
    "    return f'Speaker {speaker}: {text}'\n",
    "\n",
    "def transcribe_audio(audio_path, num_speakers):\n",
    "    preprocess_audio(audio_path)\n",
    "    transcript_df = convert_audio_to_dataframe(audio_path)\n",
    "    segments_df = perform_diarization('mono.wav', num_speakers)\n",
    "\n",
    "    segments_list = segments_df[['start', 'speaker']].to_dict(orient='records')\n",
    "\n",
    "    for segment in segments_list:\n",
    "        input_time = segment['start']\n",
    "        segment_id = transcript_df.iloc[\n",
    "            (transcript_df['start'] - input_time).abs().idxmin()\n",
    "        ]['id']\n",
    "        transcript_df.loc[transcript_df['id'] == segment_id, 'speaker'] = segment['speaker']\n",
    "\n",
    "    transcript_df['speaker'].fillna(method='ffill', inplace=True)\n",
    "    transcript_df['n1'] = transcript_df['speaker'] != transcript_df['speaker'].shift(1)\n",
    "    transcript_df['speech'] = transcript_df['n1'].cumsum()\n",
    "    grouped_df = transcript_df.groupby(['speech', 'speaker'])['text'].apply('\\n'.join).reset_index()\n",
    "\n",
    "    grouped_df['speaker'] = grouped_df['speaker'].astype(int)\n",
    "    grouped_df['output'] = grouped_df.apply(format_transcript, axis=1)\n",
    "\n",
    "    lines = grouped_df['output'].values.tolist()\n",
    "\n",
    "    os.remove('mono.wav')\n",
    "\n",
    "    return '\\n'.join(lines)\n",
    "\n",
    "def audio_folder_organize(folder_path):\n",
    "    audio_dirs = [\n",
    "        os.path.join(folder_path, file_name)\n",
    "        for file_name in os.listdir(folder_path)\n",
    "        if file_name.endswith(('.mp3', '.wav'))\n",
    "    ]\n",
    "\n",
    "    text_dirs = [file_name[:-3] + 'txt' for file_name in audio_dirs]\n",
    "\n",
    "    return audio_dirs, text_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Audio Transcription with Speaker Diarization { display-mode: \"form\" }\n",
    "\n",
    "#@markdown *Specify the number of speakers presented in your audio file*\n",
    "\n",
    "num_speakers = 2 #@param [2,3,4,5,6,7,8,9]\n",
    "\n",
    "#@markdown *Choose whether to transcribe 1 file or ALL audio files IN A FOLDER*\n",
    "\n",
    "from_file_or_folder = \"Audio File\" #@param [\"Audio File\",\"Folder with Audio Files\"]\n",
    "\n",
    "#@markdown *Copy the path to the Audio File or to the Folder (according to the previous choice)*\n",
    "\n",
    "path = \"/content/untitled.wav\" #@param {type:\"string\"}\n",
    "\n",
    "#@markdown **ATTENTION!** RULES FOR YOUR AUDIO FILES\n",
    "#@markdown *   Upload your files either into Colab Session Storage or (recommended) mount your google drive to use files from your own storage\n",
    "#@markdown *   Sometimes Google Colab can disconnect you - that is why it is better to use your own drive folder to not miss the files that were transcribed\n",
    "#@markdown *   Only WAV and MP3 formats are acceptable, use online converters if you have something else\n",
    "#@markdown *   Do not use the same names for the audio files in the folder\n",
    "#@markdown *   Remove all the spaces and use only English letters in the names of the audio files e.g. <s>\"1 - Иван Иванов - Интервью.mp3\"</s> --> \"1-Ivan_Ivanov-Interview.mp3\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------\n",
    "# ----------------------WHY R U RUNNING---------------------------\n",
    "# ----------------------------------------------------------------\n",
    "\n",
    "if from_file_or_folder == \"Audio File\":\n",
    "\n",
    "  result = transcribe_audio(path, num_speakers)\n",
    "  with open(f\"{path[:-3]}txt\", 'w', encoding='utf-8') as f:\n",
    "    f.write(result)\n",
    "\n",
    "else:\n",
    "  audio_dirs, text_dirs = audio_folder_organize(path)\n",
    "\n",
    "  for i in range(0,len(audio_dirs)):\n",
    "    result = transcribe_audio(audio_dirs[i],num_speakers)\n",
    "    with open(text_dirs[i], 'w', encoding='utf-8') as f:\n",
    "      f.write(result)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
